{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd \n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from AgentFactory import AgentFactory\n",
    "from utils import clear_json\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path: str = \"configs/conf_LLaVA.json\"\n",
    "# config_path: str = \"configs/conf_LLaMA3.json\"\n",
    "# config_path: str = \"configs/conf_DeepSeek.json\"\n",
    "config_path: str = \"configs/conf_GPT.json\"\n",
    "config = json.load(open(config_path, \"r\"))\n",
    "config = config[\"model\"]\n",
    "\n",
    "agent_factory = AgentFactory()\n",
    "agent = agent_factory.create_agent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_list = pd.read_excel('TedoneItemAssignmentTable30APR21.xlsx')\n",
    "\n",
    "# def filter_by_b_frequency(df: pd.DataFrame, n: int,\n",
    "#                           col_a: str = 'A', col_b: str = 'B') -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Delete rows in df where col_a is related to rare values ( < n ) in col_b.\n",
    "#     \"\"\"\n",
    "#     rare_bs = df[col_b].value_counts()[lambda s: s < n].index\n",
    "#     related_as = df.loc[df[col_b].isin(rare_bs), col_a].unique()\n",
    "#     mask_drop = df[col_a].isin(related_as)\n",
    "#     return df.loc[~mask_drop].copy()\n",
    "\n",
    "# N = 9\n",
    "# left_labels_num = len(multi_list[\"label\"].value_counts())\n",
    "# while True:\n",
    "#     multi_list = filter_by_b_frequency(multi_list, N, \"instrument\", \"label\")\n",
    "#     if left_labels_num == len(multi_list[\"label\"].value_counts()):\n",
    "#         break\n",
    "#     left_labels_num = len(multi_list[\"label\"].value_counts())\n",
    "\n",
    "instuments = multi_list['instrument'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments: 100%|██████████| 23/23 [00:09<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing instrument: 16PF\n",
      "File output/GPT/16PF.jsonl already exists, skipping.\n",
      "Processing instrument: 6FPQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:   8%|▊         | 3/36 [06:52<1:15:37, 137.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002965\n",
      "Processing instrument: 7FACTOR\n",
      "File output/GPT/7FACTOR.jsonl already exists, skipping.\n",
      "Processing instrument: AB5C\n",
      "File output/GPT/AB5C.jsonl already exists, skipping.\n",
      "Processing instrument: Barchard2001\n",
      "File output/GPT/Barchard2001.jsonl already exists, skipping.\n",
      "Processing instrument: BFAS\n",
      "File output/GPT/BFAS.jsonl already exists, skipping.\n",
      "Processing instrument: BFAS-20\n",
      "File output/GPT/BFAS-20.jsonl already exists, skipping.\n",
      "Processing instrument: BIDR\n",
      "File output/GPT/BIDR.jsonl already exists, skipping.\n",
      "Processing instrument: BIS_BAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  28%|██▊       | 10/36 [08:20<17:57, 41.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020050000000000003\n",
      "Processing instrument: Buss1980\n",
      "File output/GPT/Buss1980.jsonl already exists, skipping.\n",
      "Processing instrument: Cacioppo1982\n",
      "File output/GPT/Cacioppo1982.jsonl already exists, skipping.\n",
      "Processing instrument: CAT-PD\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "text: I'm really sorry to hear that you're feeling this way. It's crucial to talk to someone who can offer support, like a mental health professional.\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "text: I'm very sorry to hear that you're feeling this way. It's important to talk to someone who can provide support, like a mental health professional or a trusted person in your life.\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "text: I'm sorry to hear that you're feeling this way. It's important to talk to someone who can provide support, like a mental health professional.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  36%|███▌      | 13/36 [14:37<26:11, 68.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023750000000000004\n",
      "Processing instrument: Chapman1986\n",
      "File output/GPT/Chapman1986.jsonl already exists, skipping.\n",
      "Processing instrument: CPI\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "text: I'm sorry, I need a more specific statement or question related to a personality trait for the test. Could you please provide that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  42%|████▏     | 15/36 [24:13<41:53, 119.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023850000000000004\n",
      "Processing instrument: Foa1998\n",
      "File output/GPT/Foa1998.jsonl already exists, skipping.\n",
      "Processing instrument: Foa2002\n",
      "File output/GPT/Foa2002.jsonl already exists, skipping.\n",
      "Processing instrument: Goldberg1999\n",
      "File output/GPT/Goldberg1999.jsonl already exists, skipping.\n",
      "Processing instrument: HEXACO_PI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  53%|█████▎    | 19/36 [30:38<31:15, 110.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00175\n",
      "Processing instrument: Hoyle2002\n",
      "File output/GPT/Hoyle2002.jsonl already exists, skipping.\n",
      "Processing instrument: HPI\n",
      "File output/GPT/HPI.jsonl already exists, skipping.\n",
      "Processing instrument: HPI-HIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  61%|██████    | 22/36 [36:37<26:24, 113.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017150000000000002\n",
      "Processing instrument: IPIP-IPC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  64%|██████▍   | 23/36 [37:40<23:08, 106.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017500000000000003\n",
      "Processing instrument: JPI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  67%|██████▋   | 24/36 [40:56<24:04, 120.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014300000000000003\n",
      "Processing instrument: Levenson1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  69%|██████▉   | 25/36 [42:37<21:26, 116.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018700000000000001\n",
      "Processing instrument: MPQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  72%|███████▏  | 26/36 [45:17<20:55, 125.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00169\n",
      "Processing instrument: NEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  75%|███████▌  | 27/36 [50:51<25:52, 172.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019150000000000003\n",
      "Processing instrument: NEO5-20\n",
      "File output/GPT/NEO5-20.jsonl already exists, skipping.\n",
      "Processing instrument: ORAIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all instuments:  81%|████████  | 29/36 [57:00<20:39, 177.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015300000000000001\n",
      "Processing instrument: ORVIS\n",
      "File output/GPT/ORVIS.jsonl already exists, skipping.\n",
      "Processing instrument: Radloff1977\n",
      "File output/GPT/Radloff1977.jsonl already exists, skipping.\n",
      "Processing instrument: Rosenberg1965\n",
      "File output/GPT/Rosenberg1965.jsonl already exists, skipping.\n",
      "Processing instrument: Scheier1994\n",
      "File output/GPT/Scheier1994.jsonl already exists, skipping.\n",
      "Processing instrument: Snyder1974\n",
      "File output/GPT/Snyder1974.jsonl already exists, skipping.\n",
      "Processing instrument: Span2002\n",
      "File output/GPT/Span2002.jsonl already exists, skipping.\n",
      "Processing instrument: TCI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [1:04:32<00:00, 107.58s/it][1:04:32<00:00, 102.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00203\n",
      "Processing instrument: VIA\n",
      "File output/GPT/VIA.jsonl already exists, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Questionnaire.IPIPtest import IPIPTest\n",
    "\n",
    "ProgressBar = tqdm(total=len(instuments), desc=\"Processing all instuments\")\n",
    "\n",
    "for instrument in tqdm(instuments):\n",
    "    ProgressBar.update(1)\n",
    "    print(f\"Processing instrument: {instrument}\")\n",
    "    \n",
    "    save_path = f\"output/{config['template_type']}/{instrument}.jsonl\"\n",
    "    if Path(save_path).exists():\n",
    "        print(f\"File {save_path} already exists, skipping.\")\n",
    "        continue\n",
    "\n",
    "    qn = IPIPTest(multi_list, instrument)\n",
    "\n",
    "    for no, q in enumerate(qn.questions):\n",
    "        \n",
    "        agent.reset_msg_history()\n",
    "        agent.instruction = config[\"system_msg\"]\n",
    "        prompt = [\n",
    "            {\"type\": \"text\", \"text\": q},\n",
    "        ]\n",
    "        response, text = agent.get_response(prompt)\n",
    "\n",
    "        try:\n",
    "            dict = json.loads(clear_json(text))\n",
    "            qn.record_answer(no, dict)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(f\"text: {text}\")\n",
    "            continue\n",
    "\n",
    "    # final_output = qn.analyze()\n",
    "    qn.save_to_jsonl(f\"output/{config['template_type']}/{instrument}.jsonl\")\n",
    "    print(agent.llm.total_cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001335\n"
     ]
    }
   ],
   "source": [
    "print(agent.llm.total_cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 44/44 [02:42<00:00,  3.69s/it]\n",
      "61it [01:43,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# from Questionnaire.HEXACO import HEXACO\n",
    "\n",
    "# hexaco = HEXACO()\n",
    "\n",
    "# ProgressBar = tqdm(total=len(hexaco.get_questions()), desc=\"Processing HEXACO Questions\")\n",
    "# for no, q in tqdm(enumerate(hexaco.get_questions())):\n",
    "#     ProgressBar.update(1)\n",
    "\n",
    "#     agent.reset_msg_history()\n",
    "#     agent.instruction = config[\"system_msg\"]\n",
    "#     prompt = [\n",
    "#         {\"type\": \"text\", \"text\": q},\n",
    "#     ]\n",
    "#     response, text = agent.get_response(prompt)\n",
    "\n",
    "#     try:\n",
    "#         dict = json.loads(clear_json(text))\n",
    "#         hexaco.record_answer(no, dict)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "#         print(f\"text: {text}\")\n",
    "#         continue\n",
    "\n",
    "# final_output_hex = hexaco.analyze()\n",
    "# hexaco.save_to_jsonl(f\"output/HEXACO_{config['template_type']}.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EMO_CTRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
